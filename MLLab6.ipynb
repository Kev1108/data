{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:right;color:navy\">Machine Learning & Data Analysis &nbsp;  &nbsp;  &nbsp; December 10, 2021</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning &nbsp; &nbsp;\n",
    "\n",
    "\n",
    "## Lab 6: Validation, Metrics and Estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上次我們討論了 KFold 及 StratifiedKFold 這兩個 splitter class 資料分組的方式，利用分組資料對估計量模型做交叉驗證(cross-validation)，來解決過擬合(overfitting）問題，在練習題當中，我們嘗試寫了一個函數\n",
    "\n",
    "    validate_score(estimator, X, y, scoring=None, cv=10)  \n",
    "處理交叉驗證的過程，但其實 sklearn 有可以直接取得交叉驗證結果的方法，使用方法與我們上次寫的函數非常類似，我們今天介紹兩個交叉驗證的方法，分別為 [cross_val_score](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score) 與 [cross_validate](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html#sklearn.model_selection.cross_validate)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可參考官網說明\n",
    "\n",
    "* [sklearn.model_selection.cross_val_score]( https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html)  \n",
    "* [sklearn.model_selection.cross_validate]( https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html#sklearn.model_selection.)\n",
    "\n",
    " \n",
    "[cross_val_score](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score) 傳回一個長度為 k(k-fold) 的 array，每一個分量分別是估計量模型在這 k 個 validate set 上的準確度。  \n",
    "scores : array of float, shape=(len(list(cv))\n",
    "\n",
    "[cross_validate](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html#sklearn.model_selection.cross_validate)。\n",
    "傳回一個 dictionary，key 為 test_score、train_score、fit_time、score_time，value 為長度為 k(k-fold) 的 array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Cross Validation - cross_val_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 匯入 load_iris 函數\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# 匯入我們想用的  class，我們使用 knn，可設定 n_neighbors=5\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# 匯入 cross_val_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# 取得資料\n",
    "iris = load_iris()\n",
    "\n",
    "# 依慣例，我們以 X 來儲存 data\n",
    "X = iris.data\n",
    "\n",
    "# 以 y 來儲存 target\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 設定 10-fold 的 cross-validation (cv = 10)，KNN 的 k=5 ( n_neighbors = 5)\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "scores = cross_val_score(knn, X, y, cv=10, scoring='accuracy')\n",
    "\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 當 cv 為 int 時，這個函數預設使用 Stratified k-fold 來計算 Model 的準確度，\n",
    "* 也可以將 cv 設定為 KFold 或 StratifiedKFold， 強制使用指定的 splitter class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "kf = KFold(10)\n",
    "skf = StratifiedKFold(10)\n",
    "\n",
    "scores_kf = cross_val_score(knn, X, y, cv=kf, scoring='accuracy')\n",
    "print('Use KFold : \\n', scores_kf)\n",
    "scores_skf = cross_val_score(knn, X, y, cv=skf, scoring='accuracy')\n",
    "print('Use StratifiedKFold : \\n',scores_skf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接著，計算這 10 個 fold 所得到的準確度的平均值:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Use KFold : ',scores_kf.mean())\n",
    "print('Use StratifiedKFold : ',scores_skf.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1 \n",
    "請同學分別使用 KFold 、 StratifiedKFold 兩種 splitter class 資料分組方法，設定 10-fold，以上面的 cross_val_score 來計算 KNN 的 K 設定為 1 ~ 30 的每一個 K 的 cross_val_score 的平均值 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1 \n",
    "# 同學應該得到 30 個平均值的數字，請放置於兩個 List 中\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "請同學以 Exercise 1 得到的 List 為 y 座標，k (1 ~ 30) 為 x 座標，使用 Matplotlib 繪製折線圖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2 \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "請同學觀察上面的 Exercise，最好的 KNN Model  k = ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "也可以使用 cross_val_score 來計算 Logistic Regression 的 Model :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "請同學以 Logistic Regression 來做 Iris Dataset 的 Model，並以 cross_val_score 來得到 10 個準確度的值 (cv = 10)，計算平均值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上面的計算結果，Logistic Regression 或 KNN 哪一個較好?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Cross Validation - cross_validate\n",
    "使用  \n",
    "[cross_validate](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html#sklearn.model_selection.cross_validate)。\n",
    "傳回一個 dictionary，key 可能為 test_score、train_score、fit_time、score_time，value 為長度為 k(k-fold) 的 array。可以設定參數 return_train_score=True 如果要得到 train_score。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "scores = cross_validate(knn, X, y, cv=10, scoring='accuracy', return_train_score=True)\n",
    "\n",
    "print(scores.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scores['test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scores['train_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們等一下會再回到 cross_validate 的討論，介紹進一步 cross_validate 的功能。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Models -- Metrics\n",
    "在模型做交叉驗證(cross-validation)時，有一個 scoring 參數，控制著估計器的準確度評估過程中使用什麼樣的測度指標(metric)，例如參數 scoring='accuracy'，表示我們使用 metrics.accuracy_score 來檢驗 knn model 的準確度；sklearn 有許多 metrics methods，可以用來評估 Model 的準確度，請參考 sklearn 的 metrics :\n",
    "\n",
    "https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics\n",
    "\n",
    "這些測度指標(metrics)可依照不同的問題分為 : 分類指標(Classification metrics)，多標籤排序指標(Multilabel ranking metrics)，迴歸指標(Regression metrics)，以及聚類指標(Clustering metrics)。\n",
    "\n",
    "我們討論:  \n",
    "分類指標\n",
    "\n",
    "    metrics.accuracy_score\n",
    "    metrics.balanced_accuracy_score\n",
    "    metrics.f1_score\n",
    "    metrics.roc_auc_score\n",
    "    metrics.confusion_matrix\n",
    "    \n",
    "迴歸指標      \n",
    "\n",
    "    metrics.explained_variance_score\n",
    "    metrics.mean_absolute_error\n",
    "    metrics.mean_squared_error\n",
    "    metrics.r2_score\n",
    "    \n",
    "請同學讀一下文件說明，試試看能否做一下 Model 的 Evaluation!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Classification metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有些 metrics 是用來做 binary classification tasks 準確度評估 (例如 f1_score, roc_auc_score)。 在這些情況下，預設情況下僅評估 positive label （正標籤），positive label（正類）預設標記為 1 (可以通過 pos_label 參數進行配置)。  \n",
    "\n",
    "將 binary metric （二分指標）擴展為 multiclass （多類）或 multilabel （多標籤）問題時，資料將被視為二分問題的集合，每個類都有一個binary metric。 然後在整個類中計算所有二分指標的平均值(average binary metric calculations across the set of classes)， 這些不同的計算平均值的策略在某些特定場景中可能會用到。 如果可用，您應該使用 average 參數來選擇某個平均策略。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 Accuracy score\n",
    "函數 [accuracy_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html#sklearn.metrics.accuracy_score) 計算 accuracy, 也就是計算正確預測的比例(默認)或數量(normalize=False)。\n",
    "\n",
    "在多標籤分類中，該函數返回子集的準確率(subset accuracy)。對某個樣本的預測標籤的整個集合與該樣本真正的標籤集合嚴格匹配， 那麼子集準確率就是1.0,反之 子集準確率為0.0。\n",
    "\n",
    "如果 $\\hat{y}_i$ 是第 i 個樣本的預測值, 並且 $y_i$ 是對應的真實值, 則在 $n_{\\text{samples}}$ 個樣本上估計的正確預測的比例(the fraction of correct predictions)定義如下：\n",
    "\n",
    "$$\\texttt{accuracy}(y, \\hat{y}) = \\frac{1}{n_\\text{samples}} \\sum_{i=0}^{n_{\\text{samples }\\,\\,\\, } -1} 1(\\hat{y}_i = y_i)$$\n",
    "\n",
    "其中 $1(x)$ 是 indicator function，注意，$y_i$ 是一個 $n$ 維的向量，$n$ 是標籤的數目。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### binary classification metric （二分指標）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_test = np.array([1]*90+[0]*10)\n",
    "y_pred = np.array([1]*90+[1]*10)\n",
    "#y_test\n",
    "\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_test = np.array([0]*90+[1]*10)\n",
    "y_pred = np.array([0]*90+[0]*10)\n",
    "#y_test\n",
    "\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### multiclass classification metric （多類）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_test = np.array([1]*90+[0,2]*5)\n",
    "y_pred = np.array([1]*90+[1]*10)\n",
    "#y_test\n",
    "\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### multilabel classification metric (多標籤分類) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_test = np.array([[1,1]]*90+[[0,1]]*10)\n",
    "y_pred = np.ones((100, 2))\n",
    "#y_test\n",
    "\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 Balance accuracy score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<img src=\"http://140.133.61.216/ML/Lab/img/Lecture-04-Cross-Validation-Metrics-and-Estimators-1.png\" />\n",
    "https://en.wikipedia.org/wiki/Sensitivity_and_specificity\n",
    "\n",
    "\n",
    "* sensitivity(靈敏度), recall, hit rate, or true positive rate (TPR)\n",
    "${\\displaystyle \\mathrm {TPR} ={\\frac {\\mathrm {TP} }{\\mathrm {P} }}={\\frac {\\mathrm {TP} }{\\mathrm {TP} +\\mathrm {FN} }}=1-\\mathrm {FNR} }{\\displaystyle \\mathrm {TPR} ={\\frac {\\mathrm {TP} }{\\mathrm {P} }}={\\frac {\\mathrm {TP} }{\\mathrm {TP} +\\mathrm {FN} }}=1-\\mathrm {FNR} }$  \n",
    "\n",
    "\n",
    "* specificity(特異度), selectivity or true negative rate (TNR)  \n",
    "${\\displaystyle \\mathrm {TNR} ={\\frac {\\mathrm {TN} }{\\mathrm {N} }}={\\frac {\\mathrm {TN} }{\\mathrm {TN} +\\mathrm {FP} }}=1-\\mathrm {FPR} }{\\displaystyle \\mathrm {TNR} ={\\frac {\\mathrm {TN} }{\\mathrm {N} }}={\\frac {\\mathrm {TN} }{\\mathrm {TN} +\\mathrm {FP} }}=1-\\mathrm {FPR} }$  \n",
    "\n",
    "\n",
    "* accuracy (ACC)  \n",
    "${\\displaystyle \\mathrm {ACC} ={\\frac {\\mathrm {TP} +\\mathrm {TN} }{\\mathrm {P} +\\mathrm {N} }}={\\frac {\\mathrm {TP} +\\mathrm {TN} }{\\mathrm {TP} +\\mathrm {TN} +\\mathrm {FP} +\\mathrm {FN} }}}$  \n",
    "\n",
    "\n",
    "* balanced accuracy (BA)  \n",
    "${\\displaystyle \\mathrm {BA} ={\\frac {TPR+TNR}{2}}}{\\displaystyle \\mathrm {BA} ={\\frac {TPR+TNR}{2}}}$  \n",
    "\n",
    "\n",
    "* F1 score  \n",
    "is the harmonic mean of precision and sensitivity  \n",
    "${\\displaystyle \\mathrm {F} _{1}=2\\cdot {\\frac {\\mathrm {PPV} \\cdot \\mathrm {TPR} }{\\mathrm {PPV} +\\mathrm {TPR} }}={\\frac {2\\mathrm {TP} }{2\\mathrm {TP} +\\mathrm {FP} +\\mathrm {FN} }}}\n",
    "$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "balanced_accuracy_score 可以避免在不平衡資料集上作出誇大的性能估計。對均衡資料集， 該函數的得分與準確率得分是相等的。\n",
    "\n",
    "在二分類情況下, balanced accuracy 等價於 sensitivity (靈敏度:true positive rate) 和 specificity (特異度:true negative rate) 的算術平均值, 或者 the area under the ROC curve with binary predictions rather than scores.\n",
    "\n",
    "如果分類器在兩個類上都表現的一樣好，該函數就會退化為傳統的準確率 (i.e., 正確預測數量除以總的預測數量).\n",
    "\n",
    "作為對比, 如果傳統的準確率(conventional accuracy)比較好，僅僅是因為分類器利用了一個不均衡測試集，此時 balanced_accuracy,將會近似地掉到 $\\frac{1}{\\text{n_classes}}$。\n",
    "\n",
    "得分的範圍是 0 到 1, 或者當使用 adjusted=True 時，得分被縮放到 從  到 1, 包括邊界的, 隨機條件下性能得分為0.\n",
    "\n",
    "如果 $y_i$ 是第 $i$ 個樣本的真值，並且 $w_i$ 是對應的樣本權重，然後我們調整樣本權重到 :\n",
    "$$\\hat{w}_i = \\frac{w_i}{\\sum_j{1(y_j = y_i) w_j}}$$\n",
    "其中 $1(x)$  是 indicator function。 給定樣本 $i$ 的預測值 $\\hat{y}_i$ , balanced accuracy 如下定義：\n",
    "$$\\texttt{balanced-accuracy}(y, \\hat{y}, w) = \\frac{1}{\\sum{\\hat{w}_i}} \\sum_i 1(\\hat{y}_i = y_i) \\hat{w}_i$$\n",
    "\n",
    "\n",
    "請參考  \n",
    "[balanced_accuracy_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.balanced_accuracy_score.html#sklearn.metrics.balanced_accuracy_score)  \n",
    "[User Guide](https://scikit-learn.org/stable/modules/model_evaluation.html#balanced-accuracy-score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### binary classification metric （二分指標）\n",
    "比較 accuracy、balance-accuracy 兩者的差異  \n",
    "不平衡資料集上作出誇大的性能估計"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "y_test = np.array([1]*90+[0]*10)\n",
    "y_pred = np.array([1]*90+[1]*10)\n",
    "#y_test\n",
    "print('The accuracy is: ', accuracy_score(y_test,y_pred))\n",
    "print('The balance accuracy is: ', balanced_accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "y_test = np.array([1]*90+[0]*10)\n",
    "y_pred = np.array([1]*85+[0]*10+[1]*5)\n",
    "#y_test\n",
    "\n",
    "print('The accuracy is: ', accuracy_score(y_test,y_pred))\n",
    "print('The balance accuracy is: ', balanced_accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "y_test = np.array([1]*90+[0]*10)\n",
    "y_pred = np.array([1]*80+[0]*20)\n",
    "#y_test\n",
    "\n",
    "print('The accuracy is: ', accuracy_score(y_test,y_pred))\n",
    "print('The balance accuracy is: ', balanced_accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果分類器在兩個類上都表現的一樣好，該函數就會退化為傳統的準確率 (i.e., 正確預測數量除以總的預測數量)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "y_test = np.array([1]*90+[0]*10)\n",
    "y_pred = np.array([1]*81+[0]*18+[1])\n",
    "#y_test\n",
    "\n",
    "print('The accuracy is: ', accuracy_score(y_test,y_pred))\n",
    "print('The balance accuracy is: ', balanced_accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "對均衡資料集， 該函數的得分與準確率得分是相等的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "y_test = np.array([1]*50+[0]*50)\n",
    "y_pred = np.array([1]*60+[0]*40)\n",
    "#y_test\n",
    "\n",
    "print('The accuracy is: ', accuracy_score(y_test,y_pred))\n",
    "print('The balance accuracy is: ', balanced_accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### multiclass classification metric （多類）\n",
    "不平衡資料集上作出誇大的性能估計"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_test = np.array([1]*90+[0,2]*5)\n",
    "y_pred = np.array([1]*90+[1]*10)\n",
    "#y_test\n",
    "\n",
    "print('The accuracy is: ', accuracy_score(y_test,y_pred))\n",
    "print('The balance accuracy is: ', balanced_accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.3 Precision, recall and F-measures\n",
    "直觀地講, 精度(precision) 指的是分類器不會把負樣本標記為正樣本的能力； 召回率(或叫 查全率 recall) 指的是分類器找到資料集中所有的正樣本的能力。  \n",
    "$\\text{precision} = \\frac{tp}{tp + fp},$  \n",
    "$\\text{recall} = \\frac{tp}{tp + fn},$\n",
    "\n",
    "F-度量(F-measure (包括  和  度量) ) 可被解釋為精度(precision)和 查全率(recall)的加權調和均值(weighted harmonic mean)。 \n",
    "\n",
    "$$F_\\beta = (1 + \\beta^2) \\frac{\\text{precision} \\times \\text{recall}}{\\beta^2 \\text{precision} + \\text{recall}}$$\n",
    "\n",
    "$F_0 = \\text{precision}$。當 $\\beta=1$ 時, recall 和 precision 在 $F_1$ 的計算中是同等重要的。\n",
    "\n",
    "請參考  \n",
    "[fbeta_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.fbeta_score.html#sklearn.metrics.fbeta_score)  \n",
    "[f1_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "from sklearn.metrics import f1_score, fbeta_score, precision_score\n",
    "y_test = np.array([1]*90+[0]*10)\n",
    "y_pred = np.array([1]*90+[1]*10)\n",
    "#y_test\n",
    "print('The accuracy is: ', accuracy_score(y_test,y_pred))\n",
    "print('The balance accuracy is: ', balanced_accuracy_score(y_test,y_pred))\n",
    "print('The precision is: ', precision_score(y_test,y_pred))\n",
    "print('The F_0 score is: ', fbeta_score(y_test,y_pred,beta=0.01))\n",
    "print('The F_1 score is: ', f1_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "from sklearn.metrics import f1_score, fbeta_score, precision_score\n",
    "y_test = np.array([1]*90+[0]*10)\n",
    "y_pred = np.array([1]*85+[0]*10+[1]*5)\n",
    "#y_test\n",
    "print('The accuracy is: ', accuracy_score(y_test,y_pred))\n",
    "print('The balance accuracy is: ', balanced_accuracy_score(y_test,y_pred))\n",
    "print('The precision is: ', precision_score(y_test,y_pred))\n",
    "print('The F_0 score is: ', fbeta_score(y_test,y_pred,beta=0.01))\n",
    "print('The F_1 score is: ', f1_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'> **將上列資料 0 與 1 互換**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "from sklearn.metrics import f1_score, fbeta_score, precision_score\n",
    "y_test = np.array([0]*90+[1]*10)\n",
    "y_pred = np.array([0]*85+[1]*10+[0]*5)\n",
    "#y_test\n",
    "print('The accuracy is: ', accuracy_score(y_test,y_pred))\n",
    "print('The balance accuracy is: ', balanced_accuracy_score(y_test,y_pred))\n",
    "print('The precision is: ', precision_score(y_test,y_pred))\n",
    "print('The F_0 score is: ', fbeta_score(y_test,y_pred,beta=0.01))\n",
    "print('The F_1 score is: ', f1_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "from sklearn.metrics import f1_score, fbeta_score, precision_score\n",
    "y_test = np.array([1]*90+[0]*10)\n",
    "y_pred = np.array([1]*80+[0]*20)\n",
    "#y_test\n",
    "print('The accuracy is: ', accuracy_score(y_test,y_pred))\n",
    "print('The balance accuracy is: ', balanced_accuracy_score(y_test,y_pred))\n",
    "print('The precision is: ', precision_score(y_test,y_pred))\n",
    "print('The F_0 score is: ', fbeta_score(y_test,y_pred,beta=0.01))\n",
    "print('The F_1 score is: ', f1_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'> **將上列資料 0 與 1 互換**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "from sklearn.metrics import f1_score, fbeta_score, precision_score\n",
    "y_test = np.array([0]*90+[1]*10)\n",
    "y_pred = np.array([0]*80+[1]*20)\n",
    "#y_test\n",
    "print('The accuracy is: ', accuracy_score(y_test,y_pred))\n",
    "print('The balance accuracy is: ', balanced_accuracy_score(y_test,y_pred))\n",
    "print('The precision is: ', precision_score(y_test,y_pred))\n",
    "print('The F_0 score is: ', fbeta_score(y_test,y_pred,beta=0.01))\n",
    "print('The F_1 score is: ', f1_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果分類器在兩個類上都表現的一樣好，該函數就會退化為傳統的準確率 (i.e., 正確預測數量除以總的預測數量)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "from sklearn.metrics import f1_score, fbeta_score, precision_score\n",
    "y_test = np.array([1]*90+[0]*10)\n",
    "y_pred = np.array([1]*81+[0]*18+[1])\n",
    "#y_test\n",
    "print('The accuracy is: ', accuracy_score(y_test,y_pred))\n",
    "print('The balance accuracy is: ', balanced_accuracy_score(y_test,y_pred))\n",
    "print('The precision is: ', precision_score(y_test,y_pred))\n",
    "print('The F_0 score is: ', fbeta_score(y_test,y_pred,beta=0.01))\n",
    "print('The F_1 score is: ', f1_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "對均衡資料集， 該函數的得分與準確率得分是相等的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "from sklearn.metrics import f1_score, fbeta_score, precision_score\n",
    "y_test = np.array([1]*50+[0]*50)\n",
    "y_pred = np.array([1]*60+[0]*40)\n",
    "#y_test\n",
    "print('The accuracy is: ', accuracy_score(y_test,y_pred))\n",
    "print('The balance accuracy is: ', balanced_accuracy_score(y_test,y_pred))\n",
    "print('The precision is: ', precision_score(y_test,y_pred))\n",
    "print('The F_0 score is: ', fbeta_score(y_test,y_pred,beta=0.01))\n",
    "print('The F_1 score is: ', f1_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### multiclass classification metric （多類）\n",
    "不平衡資料集上作出誇大的性能估計"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "from sklearn.metrics import f1_score, fbeta_score, precision_score\n",
    "y_test = np.array([1]*90+[0,2]*5)\n",
    "y_pred = np.array([1]*90+[1]*10)\n",
    "#y_test\n",
    "print('The accuracy is: ', accuracy_score(y_test,y_pred))\n",
    "print('The balance accuracy is: ', balanced_accuracy_score(y_test,y_pred))\n",
    "print('The precision is: ', precision_score(y_test,y_pred,average='weighted'))\n",
    "print('The F_0 score is: ', fbeta_score(y_test,y_pred,beta=0.01,average='weighted'))\n",
    "print('The F_1 score is: ', f1_score(y_test,y_pred,average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.4 Confusion matrix\n",
    "函數 confusion_matrix 通過計算混淆矩陣( confusion matrix) 來評估分類準確率。confusion matrix 的每一行(row)對應於真實的分類，每一列(column)對應於預測的分類。\n",
    "\n",
    "按照定義, 在 confusion matrix 中，$(i,j)$中存儲著實際上應該在 group $i$ 中的觀測，但是卻被預測到了group $j$ 裡面去的這些觀測的數量。\n",
    "\n",
    "請參考  \n",
    "[Confusion Matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "from sklearn.metrics import f1_score, fbeta_score, precision_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_test = np.array([1]*90+[0]*10)\n",
    "y_pred = np.array([1]*90+[1]*10)\n",
    "#y_test\n",
    "print('The accuracy is: ', accuracy_score(y_test,y_pred))\n",
    "print('The balance accuracy is: ', balanced_accuracy_score(y_test,y_pred))\n",
    "print('The precision is: ', precision_score(y_test,y_pred))\n",
    "print('The F_0 score is: ', fbeta_score(y_test,y_pred,beta=0.01))\n",
    "print('The F_1 score is: ', f1_score(y_test,y_pred))\n",
    "print('The confusion matrix is: \\n', confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "from sklearn.metrics import f1_score, fbeta_score, precision_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_test = np.array([1]*90+[0]*10)\n",
    "y_pred = np.array([1]*85+[0]*10+[1]*5)\n",
    "#y_test\n",
    "print('The accuracy is: ', accuracy_score(y_test,y_pred))\n",
    "print('The balance accuracy is: ', balanced_accuracy_score(y_test,y_pred))\n",
    "print('The precision is: ', precision_score(y_test,y_pred))\n",
    "print('The F_0 score is: ', fbeta_score(y_test,y_pred,beta=0.01))\n",
    "print('The F_1 score is: ', f1_score(y_test,y_pred))\n",
    "print('The confusion matrix is: \\n', confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'> **將上列資料 0 與 1 互換**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "from sklearn.metrics import f1_score, fbeta_score, precision_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_test = np.array([0]*90+[1]*10)\n",
    "y_pred = np.array([0]*85+[1]*10+[0]*5)\n",
    "#y_test\n",
    "print('The accuracy is: ', accuracy_score(y_test,y_pred))\n",
    "print('The balance accuracy is: ', balanced_accuracy_score(y_test,y_pred))\n",
    "print('The precision is: ', precision_score(y_test,y_pred))\n",
    "print('The F_0 score is: ', fbeta_score(y_test,y_pred,beta=0.01))\n",
    "print('The F_1 score is: ', f1_score(y_test,y_pred))\n",
    "print('The confusion matrix is: \\n', confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "from sklearn.metrics import f1_score, fbeta_score, precision_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_test = np.array([1]*90+[0]*10)\n",
    "y_pred = np.array([1]*80+[0]*20)\n",
    "#y_test\n",
    "print('The accuracy is: ', accuracy_score(y_test,y_pred))\n",
    "print('The balance accuracy is: ', balanced_accuracy_score(y_test,y_pred))\n",
    "print('The precision is: ', precision_score(y_test,y_pred))\n",
    "print('The F_0 score is: ', fbeta_score(y_test,y_pred,beta=0.01))\n",
    "print('The F_1 score is: ', f1_score(y_test,y_pred))\n",
    "print('The confusion matrix is: \\n', confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'> **將上列資料 0 與 1 互換**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "from sklearn.metrics import f1_score, fbeta_score, precision_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_test = np.array([0]*90+[1]*10)\n",
    "y_pred = np.array([0]*80+[1]*20)\n",
    "#y_test\n",
    "print('The accuracy is: ', accuracy_score(y_test,y_pred))\n",
    "print('The balance accuracy is: ', balanced_accuracy_score(y_test,y_pred))\n",
    "print('The precision is: ', precision_score(y_test,y_pred))\n",
    "print('The F_0 score is: ', fbeta_score(y_test,y_pred,beta=0.01))\n",
    "print('The F_1 score is: ', f1_score(y_test,y_pred))\n",
    "print('The confusion matrix is: \\n', confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果分類器在兩個類上都表現的一樣好，該函數就會退化為傳統的準確率 (i.e., 正確預測數量除以總的預測數量)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "from sklearn.metrics import f1_score, fbeta_score, precision_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_test = np.array([1]*90+[0]*10)\n",
    "y_pred = np.array([1]*81+[0]*18+[1])\n",
    "#y_test\n",
    "print('The accuracy is: ', accuracy_score(y_test,y_pred))\n",
    "print('The balance accuracy is: ', balanced_accuracy_score(y_test,y_pred))\n",
    "print('The precision is: ', precision_score(y_test,y_pred))\n",
    "print('The F_0 score is: ', fbeta_score(y_test,y_pred,beta=0.01))\n",
    "print('The F_1 score is: ', f1_score(y_test,y_pred))\n",
    "print('The confusion matrix is: \\n', confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'> **將上列資料 0 與 1 互換**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "from sklearn.metrics import f1_score, fbeta_score, precision_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_test = np.array([0]*90+[1]*10)\n",
    "y_pred = np.array([0]*81+[1]*18+[0])\n",
    "#y_test\n",
    "print('The accuracy is: ', accuracy_score(y_test,y_pred))\n",
    "print('The balance accuracy is: ', balanced_accuracy_score(y_test,y_pred))\n",
    "print('The precision is: ', precision_score(y_test,y_pred))\n",
    "print('The F_0 score is: ', fbeta_score(y_test,y_pred,beta=0.01))\n",
    "print('The F_1 score is: ', f1_score(y_test,y_pred))\n",
    "print('The confusion matrix is: \\n', confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "對均衡資料集， 該函數的得分與準確率得分是相等的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "from sklearn.metrics import f1_score, fbeta_score, precision_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_test = np.array([1]*50+[0]*50)\n",
    "y_pred = np.array([1]*60+[0]*40)\n",
    "#y_test\n",
    "print('The accuracy is: ', accuracy_score(y_test,y_pred))\n",
    "print('The balance accuracy is: ', balanced_accuracy_score(y_test,y_pred))\n",
    "print('The precision is: ', precision_score(y_test,y_pred))\n",
    "print('The F_0 score is: ', fbeta_score(y_test,y_pred,beta=0.01))\n",
    "print('The F_1 score is: ', f1_score(y_test,y_pred))\n",
    "print('The confusion matrix is: \\n', confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'> **將上列資料 0 與 1 互換**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "from sklearn.metrics import f1_score, fbeta_score, precision_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_test = np.array([0]*50+[1]*50)\n",
    "y_pred = np.array([0]*60+[1]*40)\n",
    "#y_test\n",
    "print('The accuracy is: ', accuracy_score(y_test,y_pred))\n",
    "print('The balance accuracy is: ', balanced_accuracy_score(y_test,y_pred))\n",
    "print('The precision is: ', precision_score(y_test,y_pred))\n",
    "print('The F_0 score is: ', fbeta_score(y_test,y_pred,beta=0.01))\n",
    "print('The F_1 score is: ', f1_score(y_test,y_pred))\n",
    "print('The confusion matrix is: \\n', confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### multiclass classification metric （多類）\n",
    "不平衡資料集上作出誇大的性能估計"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "from sklearn.metrics import f1_score, fbeta_score, precision_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_test = np.array([1]*90+[0,2]*5)\n",
    "y_pred = np.array([1]*90+[1]*10)\n",
    "#y_test\n",
    "print('The accuracy is: ', accuracy_score(y_test,y_pred))\n",
    "print('The balance accuracy is: ', balanced_accuracy_score(y_test,y_pred))\n",
    "print('The precision is: ', precision_score(y_test,y_pred,average='weighted'))\n",
    "print('The F_0 score is: ', fbeta_score(y_test,y_pred,beta=0.01,average='weighted'))\n",
    "print('The F_1 score is: ', f1_score(y_test,y_pred,average='weighted'))\n",
    "print('The confusion matrix is: \\n', confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>由上面對於各種評估方法的實作，你是否看到了各個方法的不同目的，在評估模型的時候，我們沒有辦法只利用一種評估的方法，就能斷言我們的模型是否理想。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "請改變各種不同 y_test，y_pred 的組合，觀察各個評估方法的變化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Regression metrics (迴歸指標)\n",
    "\n",
    "接下來我們討論:  \n",
    "    \n",
    "迴歸指標      \n",
    "\n",
    "    metrics.explained_variance_score\n",
    "    metrics.mean_absolute_error\n",
    "    metrics.mean_squared_error\n",
    "    metrics.r2_score\n",
    "    \n",
    "但是在討論之前，我們先來看一個迴歸的估計器。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們來看一下使用 Linear Regression 的例子。Linear Regression Model 請參考官網 :\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# read CSV file from internet\n",
    "# 這裡參數設定 index_col=0，請同學想想是為了甚麼呢?\n",
    "data = pd.read_csv('http://140.133.61.216/ML/data/Advertising.csv', index_col=0)\n",
    "\n",
    "# display the first 5 rows\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 了解一下資料\n",
    "#data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 了解一下資料\n",
    "#data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同學可以看到這份資料除了 index 外有 4 個 columns，TV、radio、newspaper、sales，其中 TV、radio、newspaper 三個 features 某單一產品的廣告費用(千元美金)，而 sales (Target 或 Response) 是賣出產品的個數(千個)。總共有 200 個 Sample，是指在 200 個市場所得到的數字。\n",
    "\n",
    "讓我們先來看看單一的 feature--TV 跟 sales 的關係 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 了解一下 TV 跟 sales  -- Data Visualization\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(\n",
    "    data['TV'],\n",
    "    data['sales']\n",
    ")\n",
    "plt.xlabel(\"Money spent on TV ads ($)\")\n",
    "plt.ylabel(\"Sales ($)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Linear Regression\n",
    "\n",
    "只考慮 TV 廣告對 sales 的影響，如果想得到一個 Linear Regression 的 Model，就是 :\n",
    "\n",
    "sales = c<sub>0</sub> + c<sub>1</sub> x TV\n",
    "\n",
    "計算並得到\"最佳\"的 c<sub>0</sub>、c<sub>1</sub>，就相當於訓練一個 Model (這裡的最佳指的是相對於原來的 Samples，這個 Model 的誤差最小)。\n",
    "\n",
    "如果已我們之前訓練 Model 的步驟，我們需要做\n",
    "\n",
    "    step 0 : 匯入資料 (得到 X、y)\n",
    "    step 1 : 匯入想用的 Model (一個 class)\n",
    "    step 2 : 建立 Model\n",
    "    step 3 : 使用 X、y 訓練 Model (fit)\n",
    "\n",
    "接著是\n",
    "\n",
    "    step 4 : 測試 (Predict Testing Set)\n",
    "    step 5 : 準確度\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X、y 很容易，應該就是 X = data['TV']，y = data['sales']\n",
    "# 但是，這裡有一點麻煩，使用 fit 時，參數 X 必須至少是 2d(array)\n",
    "# 所以要把 X = data['TV'] 轉為 2d\n",
    "\n",
    "# 請同學執行一下下面的程式，看一下 Error Message\n",
    "\n",
    "# import model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "X = data['TV']\n",
    "y = data['sales']\n",
    "\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所以我們來改變 X，以 data['TV'].values.reshape(-1, 1) 為 X，這裡的 .values 可以將 Series 或 DataFrame 轉換成 array (新版的 Pandas 建議以 to_numpy() 取代 values) \n",
    "\n",
    ".values 請參考  https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.values.html\n",
    "\n",
    ".reshape 請參考  https://docs.scipy.org/doc/numpy/reference/generated/numpy.reshape.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 改成 x = data['TV'].values.reshape(-1, 1)\n",
    "\n",
    "# import model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "X = data['TV'].values.reshape(-1, 1) \n",
    "y = data['sales']\n",
    "\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接著我們就可以 linreg 的 intercept_、coef_ 兩個 attributes 來得到 c<sub>0</sub>、c<sub>1</sub> :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c0 = linreg.intercept_\n",
    "c1 = linreg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model (這裡的 c1 是個 array，所以顯示時有個 []，可以 c1[0] 取代!!) \n",
    "\n",
    "print('Prediction = {} + {}*X'.format(c0, c1[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "這次我們的 data 並沒有做 train_test_split，所以我們直接以 X 來做 prediction :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = linreg.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5\n",
    "請試一下以 c0、c1[0] 計算上面這個 y_pred。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 5\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6\n",
    "上面得到的 Prediction = c0 + 0.c1[0]*X 代表的是這個 Linear Regression Model 的一條直線，請同學將這條線以 Matplotlib 繪製在上面的 scatter plot 上面，像這個例子 :\n",
    "\n",
    "<img src=\"http://140.133.61.216/ML/img/LinearRegression.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 6\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7\n",
    "請同學依上面的方法練習一下分析 radio 跟 sales。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 7\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Regression metrics (迴歸指標)\n",
    "\n",
    "回到我們之前 Regression metrics 的討論:  \n",
    "    \n",
    "我們來介紹下面幾個迴歸指標:      \n",
    "\n",
    "    metrics.explained_variance_score\n",
    "    metrics.mean_absolute_error\n",
    "    metrics.mean_squared_error\n",
    "    metrics.r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 Explained variance score\n",
    "函數 [explained_variance_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.explained_variance_score.html#sklearn.metrics.explained_variance_score) 計算 explained variance regression score.\n",
    "\n",
    "如果 $\\hat{y}_i$ 是 $i$-th 樣本的預測值, 並且 $y_i$ 是對應的真實目標值，$Var$ 是 Variance, 即標準差的平方, 則 explained variance 用下面的方法估計得到:\n",
    "$$\\texttt{explained_variance}(y, \\hat{y}) = 1 - \\frac{Var\\{ y - \\hat{y}\\}}{Var\\{y\\}}$$\n",
    "最好的得分是 1.0, explained variance 的值越低越不好。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'linreg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/64/5rgrc9yn5_xgbdmvn8hwq8hm0000gn/T/ipykernel_962/1379648505.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'linreg' is not defined"
     ]
    }
   ],
   "source": [
    "y_pred = linreg.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'linreg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/64/5rgrc9yn5_xgbdmvn8hwq8hm0000gn/T/ipykernel_962/4048625892.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mexplained_variance_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mexplained_variance_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'linreg' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import explained_variance_score\n",
    "\n",
    "y_pred = linreg.predict(X)\n",
    "explained_variance_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 Mean absolute error\n",
    "函數 [mean_absolute_error](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_error.html#sklearn.metrics.mean_absolute_error) 計算平均絕對誤差(mean absolute error), 它是一個對應於 絕對誤差損失 或 $l_1$-norm 損失 的期望值的風險指標。\n",
    "\n",
    "如果 $\\hat{y}_i$ 是 $i$-th 樣本的預測值, 並且 $y_i$ 是對應的真實目標值, 則在 $n_{\\text{samples}}$ 個樣本上估計的平均絕對誤差(MAE)定義如下：\n",
    "$$\\text{MAE}(y, \\hat{y}) = \\frac{1}{n_{\\text{samples}}} \\sum_{i=0}^{n_{\\text{samples}}\\,\\,\\,-1} \\left| y_i - \\hat{y}_i \\right|$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "y_pred = linreg.predict(X)\n",
    "mean_absolute_error(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3 Mean squared error\n",
    "函數 [mean_squared_error](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html#sklearn.metrics.mean_squared_error) 計算均方誤差 ( mean square error ), 是一個對應于平方（二次）誤差或損失的期望值的風險度量。\n",
    "\n",
    "如果 $\\hat{y}_i$ 是 $i$-th 樣本的預測值, 並且 $y_i$ 是對應的真實目標值, 則在 $n_{\\text{samples}}$ 個樣本上估計的均方誤差(MSE)定義如下：\n",
    "$$\\text{MSE}(y, \\hat{y}) = \\frac{1}{n_\\text{samples}} \\sum_{i=0}^{n_\\text{samples} \\,\\,\\,- 1} (y_i - \\hat{y}_i)^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_pred = linreg.predict(X)\n",
    "mean_squared_error(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.4 R² score, the coefficient of determination\n",
    "函數 [r2_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html#sklearn.metrics.r2_score) 計算 $R^2$, the coefficient of determination. 它提供了模型對樣本的預測好壞的度量。 可能的最好得分是 1.0 而且它可以取負值 (因為模型可能要多壞有多壞). 對於一個常量模型不管輸入特徵如何變化，它的預測結果總是 y 的期望值，那麼這個模型的 $R^2$ 得分將是0.0。\n",
    "\n",
    "如果 $\\hat{y}_i$ 是 $i$-th 樣本的預測值, 並且 $y_i$ 是對應的真實目標值, 則在 $n_{\\text{samples}}$ 個樣本上估計出的 R² score 定義如下：\n",
    "$$R^2(y, \\hat{y}) = 1 - \\frac{\\sum_{i=0}^{n_{\\text{samples}}\\,\\,\\, - 1} (y_i - \\hat{y}_i)^2}{\\sum_{i=0}^{n_\\text{samples}\\,\\,\\, - 1} (y_i - \\bar{y})^2}$$\n",
    "其中 $\\bar{y} =  \\frac{1}{n_{\\text{samples}}} \\sum_{i=0}^{n_{\\text{samples}}\\,\\,\\, - 1} y_i$。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "y_pred = linreg.predict(X)\n",
    "r2_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "介紹完 Metric 之後，我們再回去討論 cross_validate 進一步的用法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Cross Validation - cross_validate\n",
    "請參考 : [cross_validate](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html#sklearn.model_selection.cross_validate)。\n",
    "\n",
    "傳回一個 dictionary，key 為 test_score、train_score、fit_time、score_time，value 為長度為 k(k-fold) 的 array\n",
    "\n",
    "score 可以利用 List of String 做一連串不同 scoreing metric 的估計，scoreing metric 的名稱請參考 [scoring parameter: defining model evaluation rules](https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['fit_time', 'score_time', 'test_accuracy', 'test_balanced_accuracy'])\n"
     ]
    }
   ],
   "source": [
    "# 使用 iris 資料\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "scores = cross_validate(knn, X, y, cv=10, scoring=['accuracy','balanced_accuracy'])\n",
    "\n",
    "print(scores.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         0.93333333 1.         1.         0.86666667 0.93333333\n",
      " 0.93333333 1.         1.         1.        ]\n"
     ]
    }
   ],
   "source": [
    "print(scores['test_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         0.93333333 1.         1.         0.86666667 0.93333333\n",
      " 0.93333333 1.         1.         1.        ]\n"
     ]
    }
   ],
   "source": [
    "print(scores['test_balanced_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
